services:
  mydbserver: # This is the testing db server to be backed up
    image: postgres:13
    environment:
      POSTGRES_USER: mybackup
      POSTGRES_PASSWORD: mybackup
      POSTGRES_DB: mybackup
    volumes:
      - ./mydb:/var/lib/postgresql/data

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - ./airflow_postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:latest

  # airflow-init:
  #   image: apache/airflow:2.6.2
  #   depends_on:
  #     - postgres
  #   environment:
  #     AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  #     AIRFLOW__CORE__FERNET_KEY: "${FERNET_KEY}"
  #     AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
  #   command: >
  #     bash -c "airflow db init"

  airflow:
    image: apache/airflow:2.6.2
    depends_on:
      - postgres
      - redis
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__FERNET_KEY: "${FERNET_KEY}"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./backup:/backup
    ports:
      - "8080:8080"
    command: webserver
  
  scheduler:
    image: apache/airflow:2.6.2
    depends_on:
      - airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__CORE__FERNET_KEY:  "${FERNET_KEY}"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./backup:/backup
    command: scheduler
